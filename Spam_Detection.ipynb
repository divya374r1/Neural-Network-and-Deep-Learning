{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx/TJ6apURqgf76b9bZvVS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divya374r1/Neural-Network-and-Deep-Learning/blob/main/Spam_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Tq2s02oJow9",
        "outputId": "6816f384-4428-4508-c53e-9180d221724a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output = 0.6547534606063191\n",
            "Spam\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "# Input values\n",
        "x = [1, 0, 1]\n",
        "\n",
        "# Hidden layer neuron 1 weights\n",
        "h1 = [0.5, -0.2, 0.3]\n",
        "\n",
        "# Hidden layer neuron 2 weights\n",
        "h2 = [0.9, 0.1, -0.5]\n",
        "\n",
        "# Output neuron weights\n",
        "out = [0.7, 0.2]\n",
        "\n",
        "# Activation functions\n",
        "relu = lambda z: max(0, z)          # ReLU\n",
        "sigmoid = lambda z: 1 / (1 + math.exp(-z))   # Sigmoid\n",
        "\n",
        "# ---- Hidden layer ----\n",
        "# Neuron 1 calculation\n",
        "h1_sum = x[0]*h1[0] + x[1]*h1[1] + x[2]*h1[2]\n",
        "h1_out = relu(h1_sum)               # Apply ReLU\n",
        "\n",
        "# Neuron 2 calculation\n",
        "h2_sum = x[0]*h2[0] + x[1]*h2[1] + x[2]*h2[2]\n",
        "h2_out = relu(h2_sum)               # Apply ReLU\n",
        "\n",
        "# ---- Output layer ----\n",
        "out_sum = h1_out*out[0] + h2_out*out[1]   # Weighted sum\n",
        "\n",
        "# Final output using sigmoid\n",
        "y = sigmoid(out_sum)\n",
        "\n",
        "# ---- Print result ----\n",
        "print(\"Output =\", y)\n",
        "print(\"Spam\" if y > 0.5 else \"Not Spam\")\n"
      ]
    }
  ]
}